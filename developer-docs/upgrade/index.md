---
title: Build and Deploy
page_title: Build and Deploy
description: Build and Deploy
published: true
allowSearch: true
keywords: Upgrade, Sunbird 4.3.0
---

## Overview

This page details out the jobs required to be run as part of the upgrade from Sunbird and Vidaydaan release 4.2.0 to release 4.3.0. Use the following table to understand the jobs that need to be executed in order to successfully complete the upgrade. Any jenkins job configuration or pre-requisites mentioned under manual configuration section needs to be done first before running any of the mentioned jobs. The order of the jobs should also be run as shown below. They can be run in parallel to speed up the execution.

### Variables for Sunbird

|Variable Name|Service Name|Comments|
|-------------|------------|--------|
|ml_core_internal_access_token|ml-core|Update in `Core/common.yml` <br/>The value can be generated by command `openssl rand -hex 10`|
|ml_cloud_config|ml-core|Update in `Core/common.yml` <br> `ml_cloud_config: |` <br>&nbsp;&nbsp;`CLOUD_STORAGE=AZURE` <br>&nbsp;&nbsp;{%raw%}`AZURE_ACCOUNT_NAME="{{sunbird_public_storage_account_name}}"`{%endraw%}<br>&nbsp;&nbsp;{%raw%}`AZURE_ACCOUNT_KEY="{{sunbird_public_storage_account_key}}"`{%endraw%}<br>&nbsp;&nbsp;{%raw%}`AZURE_ACCOUNT_SAS="{{sunbird_public_storage_account_sas}}"`{%endraw%}<br>&nbsp;&nbsp;`AZURE_STORAGE_CONTAINER=samiksha`|
|Create a file with the ansible vault password which will be used in next set of commands||`vi ~/.dev-vault` <br> Enter the password of your ansible vault in the file `~/.dev-vault`|
|Remove the old keys if already present|Adminutils|`cd ansible/inventory/{env}/Core/keys` <br> `rm -rf portalv2_key*` <br> |
|Create new private keys for signing|Adminutils|`cd ansible/inventory/{env}/Core/keys` <br> `for i in {1..10}; do openssl genrsa -out temp_c$i 2048 && openssl pkcs8 -topk8 -inform PEM -in temp_c$i -out portal_anonymous_key$i -nocrypt && rm -rf temp_c$i ; done` <br> `while read -r line; do ansible-vault encrypt $line --vault-password-file ~/.dev-vault; done <<< $(ls portal_anonymous*)"` <br> `for i in {1..10}; do openssl genrsa -out temp_c$i 2048 && openssl pkcs8 -topk8 -inform PEM -in temp_c$i -out portal_loggedin_key$i -nocrypt && rm -rf temp_c$i ; done` <br> `while read -r line; do ansible-vault encrypt $line --vault-password-file ~/.dev-vault; done <<< $(ls portal_logged*)"`|
|Remove these variables from `Core/common.yml` if present|Adminutils|`kong_portalv2_consumer` <br> `adminutil__portal_keyprefix` <br> `adminutil__portal_keystart` <br> `adminutil__portal_keycount`|
|Add the new variables|Adminutils|`## AdminUtil Vars ##` <br> `adminutil__portal_anonymous_keyprefix: "portal_anonymous_key"` <br> `adminutil__portal_anonymous_keystart: 1` <br> `adminutil__portal_anonymous_keycount: 10` <br> `adminutil__portal_loggedin_keyprefix: "portal_loggedin_key"` <br> `adminutil__portal_loggedin_keystart: 1` <br> `adminutil__portal_loggedin_keycount: 10`|
|Remove these kong consumers and acls from `Core/common.yml` if present|Kong|`refreshTokenAcl:` <br>`  - refreshTokenCreate` <br><br> ## These will be present under the `kong_consumers` dictionary <br>{%raw%}`- username: portalv2` <br>&nbsp;&nbsp;`groups: "{{ kong_all_consumer_groups + refreshTokenAcl }}"` <br>&nbsp;&nbsp;`state: present` <br>`- username: portal_app` <br>&nbsp;&nbsp;`groups: "{{ potal_app_groups }}"` <br>&nbsp;&nbsp;`state: present`{%endraw%}|
|Add the new kong consumers in private repo if you are overriding the `kong_consumers`|Kong|Add these under `kong_consumers` dictionary <br>{%raw%}`- username: portal_anonymous_register` <br>&nbsp;&nbsp;`groups: "{{ portal_anonymous_register }}"` <br>&nbsp;&nbsp;`state: present` <br>`- username: portal_loggedin_register` <br>&nbsp;&nbsp;`groups: "{{ portal_loggedin_register }}"` <br>&nbsp;&nbsp;`state: present` <br>`- username: portal_anonymous` <br>&nbsp;&nbsp;`groups: "{{ anonymous_user_groups }}"` <br>&nbsp;&nbsp;`state: present` <br>`- username: portal_loggedin` <br>&nbsp;&nbsp;`groups: "{{ kong_all_consumer_groups }}"` <br>&nbsp;&nbsp;`state: present` <br>`- username: portal_anonymous_fallback_token` <br>&nbsp;&nbsp;`groups: "{{ anonymous_user_groups }}"` <br>&nbsp;&nbsp;`state: present` <br>`- username: portal_loggedin_fallback_token` <br>&nbsp;&nbsp;`groups: "{{ kong_all_consumer_groups }}"`{%endraw%} <br>&nbsp;&nbsp;`state: present` <br>|
|Add these in `Core/common.yml`|Portal| We are changing the portal session store to use redis <br> We are using using `lp-redis` ansible group IP and DB number as 3 <br> Check that no data exists in this DB first <br> Here `/3` indicates the redis DB number we want to use <br> To check if data is present in redis DB number 3, see next section <br><br> `## Portal Anonymous Sessions and Redis as a Session store ##` <br> `sunbird_kong_device_register: 'true'` <br> `sunbird_kong_device_register_anonymous: 'true'` <br> `portal_redis_connection_string: redis://:@11.3.2.18:6379/3` <br> `sunbird_session_store_type: redis` <br><br> If you are using Azure redis, add something like this <br> {%raw%}`portal_redis_connection_string: "redis://:{{portal_redis_password}}@28.0.2.96"`{%endraw%} <br><br> Define the Azure redis password in `Core/secrets.yml` <br> `portal_redis_password: "MySecretPassword"`|
|How to check if redis DB number 3 has data|Portal|SSH into `lp-redis` VM or login to Azure redis <br>`sudo su learning` # This needs to be run only in case of `lp-redis` <br> `~/redis-6.2.5/src/redis-cli` # This needs to be run only in case of `lp-redis` <br> `SELECT 3` <br> `DBSIZE` # This command will give count of keys in DB number 3 <br> `KEYS *` # This command will list all keys in DB number 3|
|Add these in `Core/secrets.yml`|Portal|Add these values after running `OnboardConsumers` job. Refer to the comments mentioned against the variables to identify the consumer name from Jenkins job. The token values for the consumer can be obtained from the Jenkins console log after running `OnboardConsumer` job <br><br> `## Portal anonymous, loggedin sessions default tokens and device register tokens ##` <br> `sunbird_anonymous_register_token:   # Use portal_anonymous_register consumer token` <br> `sunbird_loggedin_register_token:        # Use portal_loggedin_register consumer token` <br> `sunbird_anonymous_default_token:    # Use portal_anonymous_fallback_token consumer token` <br>`sunbird_logged_default_token:            # Use portal_loggedin_fallback_token consumer token`|
|Add these ACLs in `Core/common.yml` if you are overriding any of the Sunbird consumers and / or other external / custom consumers you have created|Kong|Ensure the following acls are added to desktop_device, desktop_devicev2, mobile_device, mobile_devicev2 consumers and any other consumers who require the API access <br><br> `- anonymousCertificateAccess`<br>`- anonymousContentAccess` <br>`- anonymousCourseAccess`<br>`- anonymousOrgAccess`<br>`- anonymousUserAccess` <br>`- anonymousAppAccess`|
|Add these ACLs in `Core/common.yml` if you are overriding `mobile_device_groups` consumer in your private repo|Kong|[PR - 2912](https://github.com/project-sunbird/sunbird-devops/pull/2912)|
|Upgrade the Druid VM to 10 core and above|Druid|We have 4 new druid supervisors added as part of Managed Learn module <br> Upgrade the druid middle manager VM to 10 core or above <br> Refer to ansible group `[raw-middlemanager]` for the middle manager VM IP and upgrade this VM <br> Add the below variable in `DataPipeline/common.yml` to update the middle manager worker cap <br> `# Dev druid VM upgraded to 16 core #` <br> `private_druid_configs:` <br> &nbsp;&nbsp;`raw:` <br>&nbsp;&nbsp;&nbsp;&nbsp;`druid_middlemanager_worker_cap: 16`|


### Build and Deploy for Sunbird

|Service to be Build|Build Tag|Service to Deploy|Deploy Tag|Comments|
|-------------------|---------|-----------------|----------|--------|
|||Provision/DataPipeline/PostgresDbUpdate|release-4.3.0_RC2||
|||Provision/DataPipeline/Druid|release-4.3.0_RC2<br>`service: mm`<br>`cluster: choose as per your environment configuration`||
|||Deploy/Core/KafkaSetup|release-4.3.0_RC3||
|||Deploy/Kubernetes/UploadSchemas|release-4.3.0_RC3<br>`kp_branch_or_tag: release-4.3.0_RC9`||
|Build/Core/Cassandra|release-4.3.0_RC3|Deploy/Kubernetes/Cassandra|release-4.3.0_RC3||
|||Deploy/Kubernetes/OnboardAPIs|release-4.3.0_RC3||
|||Deploy/Kubernetes/OnboardConsumers|release-4.3.0_RC3||
|Build/Core/AdminUtils|release-4.3.0_RC1|Deploy/Kubernetes/AdminUtils|release-4.3.0_RC3||
|Build/Core/Analytics|release-4.3.0_RC4|Deploy/Kubernetes/Analytics|release-4.3.0_RC3||
|Build/Core/Assessment|release-4.3.0_RC9|Deploy/Kubernetes/Assessment|release-4.3.0_RC3||
|Build/Core/Content|release-4.3.0_RC9|Deploy/Kubernetes/Content|release-4.3.0_RC3||
|||Deploy/Kubernetes/Keycloak|release-4.3.0_RC3|Redeploy same artifact as this only a deployment configuration change for telemetry PID|
|Build/Core/Learner|release-4.3.0_RC16|Deploy/Kubernetes/Learner|release-4.3.0_RC3||
|Build/Core/KnowledgeMW|release-4.3.0_RC1|Deploy/Kubernetes/KnowledgeMW|release-4.3.0_RC3||
|||Deploy/Kubernetes/KongJWTAdminUtil|release-4.3.0_RC3||
|Build/Core/Player|release-4.3.0_RC30|Deploy/Kubernetes/Player|release-4.3.0_RC3||
|Build/Core/Search|release-4.3.0_RC9|Deploy/Kubernetes/Search|release-4.3.0_RC3||
|Build/Core/Taxonomy|release-4.3.0_RC9|Deploy/Kubernetes/Taxonomy|release-4.3.0_RC3||
|Build/DataPipeline/CoreDataProducts|release-4.3.0_RC2|Deploy/DataPipeline/CoreDataProducts|release-4.3.0_RC2||
|Build/DataPipeline/EdDataProducts|release-4.3.0_RC2|Deploy/DataPipeline/EdDataProducts|release-4.3.0_RC2||
|Build/KnowledgePlatform/FlinkJobs|release-4.3.0_RC8|Deploy/KnowledgePlatform/FlinkJobs|release-4.3.0_RC6|Deploy all the jobs|
|Build/KnowledgePlatform/Learning|release-4.3.0_RC6|Deploy/KnowledgePlatform/Learning|release-4.3.0_RC6||
|Build/KnowledgePlatform/SyncTool|release-4.3.0_RC6|Deploy/KnowledgePlatform/Neo4jElasticSearchSyncTool|release-4.3.0_RC6||
|Build/KnowledgePlatform/Yarn|release-4.3.0_RC6|Deploy/KnowledgePlatform/Yarn|release-4.3.0_RC6||
|Build/Plugins/ContentPlugins|release-4.3.0_RC2|Deploy/Plugins/ContentPlugins|release-4.3.0_RC3||
|||OpsAdministration/Core/GraylogMongoImport|release-4.3.0_RC3 <br> graylog_mongo_collections: inputs,searches,views|This was deployed as part of 4.2.0 hotfix, so its not required to run if already deployed|
|Build/Mobile/Sunbird-IONIC-Mobile-App|release-4.3.0_RC20|||Required only if you are using the Sunbird mobile app|
|Build/managed-learn/gotenberg|release-4.3.0_RC1|Deploy/managed-learn/gotenberg|release-4.3.0_RC3||
|Build/managed-learn/ml-core-service|release-4.3.0_RC1|Deploy/managed-learn//ml-core-service|release-4.3.0_RC3||
|Build/managed-learn/ml-project-service|release-4.3.0_RC1|Deploy/managed-learn/ml-project-service|release-4.3.0_RC3||
|Build/managed-learn/ml-report-service|release-4.3.0_RC1|Deploy/managed-learn/ml-report-service|release-4.3.0_RC3||
|Build/managed-learn/ml-survey-service|release-4.3.0_RC1|Deploy/managed-learn/ml-survey-service|release-4.3.0_RC3||
|||Deploy/managed-learn/ml-analytics-service|release-4.3.0_RC3||
|||Deploy/DataPipeline/InternalKong|release-4.3.0_RC3<br>`option: onboard-apis`|For `image_tag` parameter, use the same tag as the previous successful job|

### Manual Configurations for Sunbird

|Manual Step|Instruction|
|--------------------|--------------------|
|Create a new mongo database for Managed Learn|<b>Note: Skip this if the database is already existing in your environment. This is required only for new setup</b><br> You can use the existing mongodb VM under the ansible group `[mongo_master]`. Login into the VM and run the following commands <br> `wget https://sunbirdpublic.blob.core.windows.net/installation/sunbird-staging-23Sep.zip` <br> `unzip sunbird-staging-23Sep.zip` <br> `mongo` <br> `use ml-survey` <br> `exit` <br> `mongorestore --gzip --db ml-survey sl-prod`|
|Create a new VM for Managed Learn with MongoDB|Choose the appropriate size of the VM based on workload. For low workload we can use `Standard D2s v3 (2 vcpus, 8 GiB memory)` (Azure). We will be using this VM IP under `[ml-analytics-service]` ansible group.|
|Create new ansible inventory in private repo|`cd ansible/inventory/{env}` <br> `mkdir managed-learn && cd managed-learn` <br> `ln -s ../Core/secrets.yml secrets.yml` <br> `ln -s ../Kubernetes/kubernetes.yaml kubernetes.yaml` <br> `ln -s ../Core/keys keys` <br> `ln -s ../Core/hosts hosts` <br> `ln -s ../Core/common.yml common.yml`|
|Add new ansible group under `ansible/inventory/env/Core/hosts`|`[ml-analytics-service]` <br> `11.3.3.4 # Managed Learn Analytics VM`|
|Create the new Jenkins jobs for Managed Learn|[PR - 2937](https://github.com/project-sunbird/sunbird-devops/pull/2937)|
|Add these APIs to private Kong API|[Private Kong APIs for Managed Learn](https://project-sunbird.atlassian.net/wiki/spaces/DevOps/pages/2961113099/Private+Kong+APIs+for+Managed+Learn)|
|Update system settings|[System Settings API](https://project-sunbird.atlassian.net/wiki/spaces/UM/pages/2945449992/SB-26932+System+Settings+config+curl+for+NIC+SMS+Provide+integration)|
|Increase rate limit for fallback portal consumers if required. When the Adminutils service goes down, Portal will use these fallback tokens<br><b>Note: You can execute this only when Adminutils service starts to fail and you start getting `429 Rate Limit Exceeded` errors|Fallback consumers for Portal are `portal_anonymous_fallback_token` and `portal_loggedin_fallback_token`<br> To increase the rate limit on a consumer level, you can run the below command inside the kong pod<br>`curl -X POST http://localhost:8001/consumers/{CONSUMER}/plugins --data "name=rate-limiting" --data "config.hour=10000" --data "config.policy=local"`|

##### Note: The below jobs are applicable only if you are running Vidyadaan infrastructure

### Build and Deploy for Vidayadaan

|Service to be Build|Build Tag|Service to Deploy|Deploy Tag|Comments|
|-------------------|---------|-----------------|----------|--------|
|||Deploy/Dock/Kubernetes/OnboardAPIs|release-dock-0.0.3_RC2||
|||Deploy/Dock/Kubernetes/OnboardConsumers|release-dock-0.0.3_RC2||
|||Deploy/Kubernetes/UploadSchemas|release-4.3.0_RC3<br>`kp_branch_or_tag: release-4.3.0_RC9`||
|Build/Dock/Assessment|release-4.3.0_RC9|Deploy/Kubernetes/Assessment|release-dock-0.0.3_RC2||
|Build/Dock/Content|release-4.3.0_RC9|Deploy/Kubernetes/Content|release-dock-0.0.3_RC2||
|Build/Dock/DockOpensaber|`github_release_tag: refs/heads/vidyadaan`<br> `creation_portal_branch: release-4.3.0`|Deploy/Kubernetes/Opensaber|release-dock-0.0.3_RC2||
|Build/Dock/Player|release-4.3.0_RC17|Deploy/Kubernetes/Player|release-dock-0.0.3_RC2||
|Build/Dock/Program|release-4.3.0_RC5|Deploy/Kubernetes/Program|release-dock-0.0.3_RC2||
|Build/Dock/Search|release-4.3.0_RC9|Deploy/Kubernetes/Search|release-dock-0.0.3_RC2||
|Build/Dock/Taxonomy|release-4.3.0_RC9|Deploy/Kubernetes/Taxonomy|release-dock-0.0.3_RC2||
|Build/Dock/KnowledgePlatform/FlinkJobs|release-4.3.0_RC8|Deploy/KnowledgePlatform/FlinkJobs|release-4.3.0_RC6|Deploy all the jobs|
|Build/Dock/KnowledgePlatform/Learning|release-4.3.0_RC6|Deploy/KnowledgePlatform/Learning|release-4.3.0_RC6||
|Build/Dock/KnowledgePlatform/Yarn|release-4.3.0_RC6|Deploy/KnowledgePlatform/Yarn|release-4.3.0_RC6||
|Build/Plugins/ContentPlugins|release-4.3.0_RC2|Deploy/Plugins/ContentPlugins|release-4.3.0_RC3||

### Manual Configurations for Vidyadaan

|Manual Step|Instruction|
|--------------------|--------------------|
|Run the migration script on Postgres OpenSaber DB|[Script](https://github.com/Sunbird-Ed/program-service/blob/release-4.3.0/src/migration/open-saber.sql)|
|Form Configurations|[SB-24915](https://project-sunbird.atlassian.net/browse/SB-24915)<br>[SB-23817](https://project-sunbird.atlassian.net/browse/SB-23817)|